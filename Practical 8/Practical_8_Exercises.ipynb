{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"float:left\">\n",
    "    <h1 style=\"width:450px\">Practical 8: </h1>\n",
    "    <h2 style=\"width:450px\">Visualisation and Linked Data</h2>\n",
    "</div>\n",
    "<div style=\"float:right\"><img width=\"100\" src=\"https://github.com/jreades/i2p/raw/master/img/casa_logo.jpg\" /></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: dotted 1px rgb(156,121,26); padding: 10px; margin: 5px; background-color: rgb(255,236,184)\"><i>Note</i>: You should download this notebook from GitHub and then save it to your own copy of the repository. I'd suggest adding it (<tt>git add Practial-...</tt>) right away and then committing (<tt>git commit -m \"Some message\"</tt>). Do this again at the end of the class and you'll have a record of everything you did, then you can <tt>git push</tt> it to GitHub.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. Find London MSOAs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grab E+W MSOA Shapefile\n",
    "\n",
    "This -- and a lot of other data besides! -- can be accessed from the [GeoPortal](https://geoportal.statistics.gov.uk/datasets/middle-layer-super-output-areas-december-2011-ew-bgc-v2). And see also my discussion on [lookup tables](https://geoportal.statistics.gov.uk/datasets/postcode-to-output-area-to-lower-layer-super-output-area-to-middle-layer-super-output-area-to-local-authority-district-december-2011-lookup-in-england-and-wales)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msoas = gpd.read_file('https://github.com/jreades/i2p/blob/master/data/src/Middle_Layer_Super_Output_Areas__December_2011__EW_BGC_V2-shp.zip?raw=true')\n",
    "msoas.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msoas.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grab the Borough Boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boros = gpd.read_file('https://github.com/jreades/i2p/blob/master/data/src/Boroughs.gpkg?raw=true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then generate the boundary for London using the `unary_union` operator (as we do here) or using the earlier [`dissolve(by=region)`](https://geopandas.org/aggregation_with_dissolve.html) approach. Consider the pros and cons of each approach in terms of performance, output format, and legibility. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldn = gpd.GeoDataFrame(gpd.GeoSeries(data=boros.unary_union, crs='epsg:27700')).rename(columns={0:'original'})\n",
    "\n",
    "# In order to ensure that we get all MSOAs _within_ London \n",
    "# we will buffer the boundary by 250m. If _cover_ were \n",
    "# easier to use then that option might be preferable.\n",
    "ldn['geometry'] = ldn.original.buffer(250)\n",
    "ldn = ldn.set_geometry('geometry')\n",
    "ldn.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1.1: Select London MSOAs using a Spatial Join\n",
    "\n",
    "Here's our first spatial join. By default it will be an _inner_ join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldn_msoas = gpd.sjoin(msoas, ldn, op='??')\n",
    "ldn_msoas.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We no longer really need to keep the full MSOA data set hanging about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(msoas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1.2: Extract Borough Names\n",
    "\n",
    "Notice that the MSOA Name _contains_ the Borough name. Use a regex (in `str.replace()`) to extract the LA name from the MSOA name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldn_msoas['Borough'] = ldn_msoas.MSOA11NM.str.replace(??,'',regex=True)\n",
    "\n",
    "# Just check results look plausible; you should have:\n",
    "# - 33 boroughs\n",
    "# - A df shape of 983 x 14\n",
    "print(ldn_msoas.Borough.unique())\n",
    "print(len(ldn_msoas.Borough.unique()))\n",
    "print(ldn_msoas.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1.3: Add MSOA Names using a Merge\n",
    "\n",
    "The House of Commons Library provides a [MSOA Names](https://visual.parliament.uk/msoanames) data set that contains locally-relevant names applied to MSOAs. These seek to connect the Census geography (OA > LSOA > MSOA > LA) to a loosely-defined 'neighbourhood'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msoa_nms = pd.read_csv('https://github.com/jreades/i2p/blob/master/data/src/MSOA-Names-1.8.csv.gz?raw=true', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(msoa_nms.columns.values)\n",
    "msoa_nms.sample(3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you've loaded the `msoa_nms` data you need to merge it with our `ldn_msoas`. You will need to deal with the fact that the left and right fields have different names and may also want to think about the `how` of the merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msoas = pd.merge(ldn_msoas, msoa_nms, ??, ??, ??)\n",
    "print(msoas.shape)\n",
    "print(type(msoas)) # You should check this -- result isn't always be a GeoDataFrame\n",
    "msoas.sample(3, random_state=42)[['OBJECTID','MSOA11CD','MSOA11NM','msoa11hclnm']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your result should be:\n",
    "\n",
    "|    | OBJECTID | MSOA11CD | MSOA11NM | msoa11hclnm |\n",
    "| -: | -------: | -------: | :------- | :---------- |\n",
    "| **810** | 811 | E02000841 | Sutton 002 | St Helier South |\n",
    "| **801** | 802 | E02000832 | Southwark 026 | Nunhead North |\n",
    "| **813** | 814 | E02000844 | Sutton 005 | The Wrythe |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tidy Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['MSOA11NMW','LONG','LAT','Shape__Are','Shape__Len','index_right',\n",
    "           'original','msoa11cd','msoa11nm','msoa11nmw','Laname','msoa11hclnmw']\n",
    "msoas.drop(columns=to_drop, inplace=True)\n",
    "print(msoas.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### And Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msoas.to_file(os.path.join('data','geo','London_MSOAs.gpkg'), driver='GPKG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. Load InsideAirbnb Data\n",
    "\n",
    "Load the InsideAirbnb data into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['id','name','price','latitude','longitude','property_type','room_type']\n",
    "df = pd.read_csv(??, usecols=cols, low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price'] = df.price.str.replace('$','').str.replace(',','').astype(float)\n",
    "df.drop(df[((df.latitude.isna())|(df.longitude.isna()))].index, axis=0, inplace=True)\n",
    "df.drop(df[((df.latitude < 40)|(df.longitude > 1))].index, axis=0, inplace=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2.1: Add Geometry and Reproject\n",
    "\n",
    "Convert the df into a GeoDataFrame named gdf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.GeoDataFrame(df, geometry=??)\n",
    "gdf = gdf.to_crs('epsg:27700')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2.2: Add LA Names to Data\n",
    "\n",
    "Associate LA (Local Authority) names to the listings using a spatial join:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_la = gpd.sjoin(gdf, boros, ??, ??)\n",
    "print(gdf_la.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gdf_la.shape)\n",
    "gdf_la.sample(3, random_state=42)[['id','name','NAME']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should have a GeoDataFrame with 74,184 rows and 15 columns and the following tabular output:\n",
    "\n",
    "|       | id | name | NAME |\n",
    "| ----: | -------: | :---------- | :---------- |\n",
    "| 66121 | 41808059 | Haverstock Hotel, Twin Room | Camden |\n",
    "| 58701 | 38685213 | Charming 1st floor two bedroom Fulham apartment| Hammersmith and Fulham |\n",
    "| 53195 | 35724891 | Lovely East End En-Suite Room in Great Location. | Tower Hamlets |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2.3: Tidy Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_la.drop(columns=['index_right','HECTARES','NONLD_AREA','ONS_INNER'], inplace=True)\n",
    "gdf_la.NAME.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's something strange about the output of `unique()` above... can you spot it? There are 15 problematic records... see if you can print them out here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf[??][['id','name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2.4: Map Problematic Listings\n",
    "\n",
    "Now see if you can map them as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = ??.plot()\n",
    "boros.plot(ax=ax, edgecolor='r', facecolor='None', alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your result should be:\n",
    "\n",
    "![](https://github.com/jreades/i2p/blob/master/lectures/img/Unmatched_Listings.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2.5: Drop Problematic Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_la.drop(index=??, axis=1, inplace=True)\n",
    "print(gdf_la.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now have 74,169 records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2.6: Check Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = gdf_la.plot(column='NAME', markersize=0.5, alpha=0.5, figsize=(10,8))\n",
    "boros.plot(ax=ax, edgecolor='r', facecolor='None', alpha=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Using Seaborn and Grouped Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3.1: A Basic Boxplot\n",
    "\n",
    "See if you can create a basic boxplot of price by room type, and then set the y-limits to 0-500 (£/night)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.set_theme(style=\"ticks\", palette=\"pastel\")\n",
    "f,ax = plt.subplots(figsize=(8,5))\n",
    "??\n",
    "sns.despine(offset=10)\n",
    "ax.??([0,500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3.2: Grouping on One Column\n",
    "\n",
    "Let's group the data on the LA name. You should get that the type is a `DataFrameGroupBy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_data = gdf_la.groupby(??)\n",
    "print(type(la_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the result here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_data.price.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3.3: A Basic Distribution Plot\n",
    "\n",
    "Although this is hardly the most robust analysis (subtracting the mean of a grouped mean from a grouped mean seems... sketchy), it's useful for quickly demonstrating a different plot type and then asking you to work out how to obtain something close to the output below using these solutions:\n",
    "\n",
    "- [Figure title](https://matplotlib.org/3.3.3/gallery/subplots_axes_and_figures/figure_title.html)\n",
    "- [How to position `suptitle`](https://stackoverflow.com/questions/55767312/how-to-position-suptitle)\n",
    "- [Label axes on Seaborn Barplot](https://stackoverflow.com/questions/31632637/label-axes-on-seaborn-barplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "ax = sns.displot((la_data.price.mean() - la_data.price.mean().mean())/la_data.price.std())\n",
    "??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your result should be close to:\n",
    "\n",
    "![](https://github.com/jreades/i2p/blob/master/lectures/img/std_boro_price.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3.4: Grouping on Multiple Columns\n",
    "\n",
    "We're now going to create a data frame grouped by LA and room type, and then use the `agg` (aggregate) function on a grouped data frame and derive several measures (Count, Sum, Mean, Median, std, Lower Quartile, and Upper Quartile) in one go from the price column. \n",
    "\n",
    "You will want to search on something like \"Multiple aggregations of the same column using pandas GroupBy.agg()\" in order to work this out. \n",
    "\n",
    "You'll also need to look at \"calculate quantile pandas aggregate\" -- depending on the solution you choose, your quantiles may or may not have the same labels as mine below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_data2 = gdf_la.groupby(??).agg(??).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_data2.sample(3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My sample gives me:\n",
    "\n",
    "|    | NAME | room_type |     |     |     |     |     |     | price |\n",
    "| -: | :--- | :-------- | --: | --: | --: | --: | --: | --: | ----: |\n",
    "|    |      |           | **count** | **sum** | **mean** | **median** | **std** | **\\<lambda_0\\>** | **\\<lambda_1\\>** |\n",
    "| 18 | Bromley | Private room | 334 | 17288.86 | 51.763054 | 36.0 | 91.390795 | 27.0 | 50.00 |\n",
    "| 42 | Greenwich | Private room | 830 | 62005.70 | 74.705663 | 38.0 | 223.600981 | 28.0 | 53.75 |\n",
    "| 36 | Enfield | Entire home/apt | 217 | 26437.72 | 121.832811 | 95.0 | 121.763967 | 70.0 | 130.00 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am _not_ cruel enough to make you work out how to convert the above to a flat index, so here's the code to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_data2.columns = la_data2.columns.droplevel(0)\n",
    "print(la_data2.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we just need to correct a few column labels manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = la_data2.columns.values\n",
    "cols[ 0] = 'name'\n",
    "cols[ 1] = 'room_type'\n",
    "cols[-2] = 'lq'\n",
    "cols[-1] = 'uq'\n",
    "la_data2.columns = cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next plot may take a while to run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "sns.despine(bottom=True, left=True)\n",
    "\n",
    "# Show each observation with a scatterplot\n",
    "# https://seaborn.pydata.org/examples/jitter_stripplot.html\n",
    "g = sns.stripplot(x=\"median\", y=\"room_type\", hue=\"name\",\n",
    "              data=la_data2, dodge=True, alpha=.25, zorder=1)\n",
    "g.legend_.remove()\n",
    "\n",
    "# Show the median of medians\n",
    "sns.pointplot(x=\"median\", y=\"room_type\",\n",
    "              data=la_data2.groupby('room_type').agg('median').reset_index(), \n",
    "              dodge=.232, join=False, palette=\"dark\",\n",
    "              markers=\"d\", scale=.75, ci=None)\n",
    "\n",
    "plt.gcf().subplots_adjust(top=0.92)\n",
    "f.suptitle('Median Price by Borough', fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3.5: Grouping on a Custom Mapping\n",
    "\n",
    "Use the map below, taken from the Centre for London's [_Housing and Inequality in London_](https://www.centreforlondon.org/wp-content/uploads/2016/08/CFLJ4292-London-Inequality-04_16_WEB_V4.pdf) (p.17) to assign each LA to one of the five regions shown. Create a grouped data frame using this mapping instead of the LA one. Do so _without_ creating a new column.\n",
    "\n",
    "![](https://github.com/jreades/i2p/blob/master/lectures/img/Borough_Mapping.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up a `mapping` dict here so that you can apply it as part of the `groupby` operation below (you should have 33 keys when done):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {}\n",
    "#I've given you the first region to start\n",
    "for b in ['Enfield','Waltham Forest','Redbridge','Barking and Dagenham','Havering','Greenwich','Bexley']:\n",
    "mapping[b]='Outer East and North East'\n",
    "??\n",
    "print(len(mapping.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group by your mapping and by `room_type`, and calculate the mean and median price only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_data3 = gdf_la.set_index('NAME').groupby([mapping,'room_type']).agg(\n",
    "    {'price':['mean','median']}\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_data3.sample(3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My output looks like this:\n",
    "\n",
    "|     | level_0 | room_type |     | price |\n",
    "| --: | :------ | :-------- | --: | ----: |\n",
    "|     |         |           | **mean** | **median** |\n",
    "| 0 | Inner East | Entire home/apt | 138.428470 | 100.0 |\n",
    "| 17 | Outer West and North West | Hotel room | 123.295429 | 85.0 |\n",
    "| 15 | Outer South | Shared room | 57.0000000 | 45.0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_data3.columns = la_data3.columns.droplevel(0)\n",
    "cols = la_data3.columns.values\n",
    "cols[0]  = 'area'\n",
    "cols[1]  = 'room_type'\n",
    "la_data3.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_data3.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See if you can produce the same plot as above but for the aggregated areas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4. Exploring an LA using Subplots\n",
    "\n",
    "Select a LA that is relevant to _you_ to explore further..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LA = 'Waltham Forest'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4.1: Spatial Join Listings and MSOAs\n",
    "\n",
    "The first thing we want to do is join MSOA identifiers in `msoas` to each listing in `gdf_la`. In both cases we want to constrain the data to only be for 'our' LA of interest. You do not have to save this to a new variable and can do the selection _as part_ of the spatial join:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msoadf  = gpd.sjoin(\n",
    "            gdf_la[??], \n",
    "            ??, \n",
    "            op=??)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4.2: Aggregate by MSOA\n",
    "\n",
    "Now aggregate the data by MSOA, deriving median price and a count of the listings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msoagrdf = msoadf.groupby('MSOA11NM').agg({'price':['median','count']}).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which level value is easier to use? 0? or 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msoagrdf.columns = msoagrdf.columns.get_level_values(1)\n",
    "msoagrdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix the missing column name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msoagrdf.rename(columns={'':'MSOA11NM', 'count':'listings'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4.3: Join on Indexes\n",
    "\n",
    "Here we see the difference between merge and join. You'll notice that `join` operates taking one data frame as the implicit 'left' table (the one which _calls_ join) while the one that is passed to the join function is, implicitly, the 'right' table. Join operates only using indexes, so you'll need to insert the code to specify the same index on both data frames, but this can be done **on-the-fly** as part of the joining operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msoa_gdf = msoagrdf.set_index(??).join(\n",
    "                ??, \n",
    "                rsuffix='_r')\n",
    "msoa_gdf.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to add a command in order to help python recognise that this should be a GeoDataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msoa_gdf.plot(column='median', legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4.4: Discover Fonts Installed\n",
    "\n",
    "I find matplotlib's use of fonts to be _profoundly_ weird. Basically, you need to investigate the 'font cache' folder and see what's listed there. Depending on how you installed the Python libraries you _might_ have access to your whole computer's fonts (if you used `conda`) or to only those free fonts that come with Linux (if you used Vagrant or Docker). This code may not even run on a PC or Mac with `conda` in which case you'll need to do some more investigating and poking around..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "loc = matplotlib.get_cachedir()\n",
    "!ls {loc}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully you will see a list of installed fonts when you run this. See if you can make sense of what this code does!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fonts = !cat {loc + '/fontlist-v330.json'}\n",
    "fonts = set(list(filter(lambda x:'\"name\"' in x, fonts)))\n",
    "fonts = [x.replace('      \"name\": \"','').replace('\",','') for x in fonts]\n",
    "print(fonts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am setting this as the 'title font' (`tfont`) to use in the output below. You can pick another font and see what happens. The format for this is a dictionary, so where you see `fontdict` in the `matplotlib` documentation this should work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfont = {'fontname':'Liberation Sans Narrow', 'horizontalalignment':'left'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5: Create at Atlas-Type Output\n",
    "\n",
    "We're now going to emulate a _bit_ of QGIS' Atlas function by creating two subplots and then adding a _third_ plot afterwards that shows where the borough is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,axes = plt.subplots(1,2,figsize=(12,8))\n",
    "\n",
    "msoa_gdf.plot(column='median', ax=axes[0], legend=True, cmap='viridis')\n",
    "msoa_gdf.copy().plot(column='listings', ax=axes[1], legend=True, cmap='plasma')\n",
    "for ax in axes:\n",
    "    ax.axis('off')\n",
    "    \n",
    "ax2 = f.add_axes([0.015, 0.7, 0.2, 0.2])\n",
    "boros.plot(facecolor='lightgrey', edgecolor='None', ax=ax2)\n",
    "boros[boros.NAME==LA].plot(facecolor='r', edgecolor='r', hatch='///', ax=ax2)\n",
    "ax2.axis('off')\n",
    "\n",
    "f.suptitle(LA, x=0.025, ha='left', size=24, **tfont)\n",
    "axes[0].set_title('Median Price', size=20, **tfont)\n",
    "axes[1].set_title('Listings', size=20, **tfont)\n",
    "\n",
    "plt.figtext(x=0.025, y=0.65, s=f\"Total Listings: {msoa_gdf.listings.sum():,.0f}\", size=14, **tfont);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bonus Achievement Unlocked!\n",
    "\n",
    "See if you can convert the above to an _actual_ atlas output: you'll want to turn this into a function so as to be able to produce (and save) the map for _every_ borough. You'll even need to parameterise the filename so that you save to _different_ PNG files..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5. Using Bokeh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 5.1: For a Chart\n",
    "\n",
    "Group the listings by Borough and Room Type, and aggregate by median price, also producing a count variable for the number of listings of each type in each Borough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_rt = gdf_la.groupby(??).agg(??).reset_index()\n",
    "la_rt.columns = ['NAME','room_type','price','listings']\n",
    "la_rt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a LA of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LA = 'Camden'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_rt[la_rt.NAME==LA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models import ColumnDataSource, HoverTool\n",
    "from bokeh.palettes import Spectral4\n",
    "from bokeh.models import CustomJS, Dropdown\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "room_types = list(la_rt[la_rt.NAME==LA].room_type.values)\n",
    "price = list(la_rt[la_rt.NAME==LA].price.values)\n",
    "boros = list(la_rt[la_rt.NAME==LA].NAME.values)\n",
    "counts = list(la_rt[la_rt.NAME==LA].listings.values)\n",
    "\n",
    "source = ColumnDataSource(data=dict(\n",
    "                                room_types=room_types, \n",
    "                                price=price, \n",
    "                                counts=counts, \n",
    "                                boros=boros, \n",
    "                                color=Spectral4))\n",
    "\n",
    "p = figure(x_range=room_types, plot_height=300, title=f\"Median Price by Room Type in {LA}\",\n",
    "           toolbar_location=None, tools=\"\")\n",
    "\n",
    "p.vbar(x='room_types', top='price', width=0.9, color='color', legend_field=\"room_types\", source=source)\n",
    "\n",
    "p.xgrid.grid_line_color = None\n",
    "p.y_range.start = 0\n",
    "\n",
    "# Add hover\n",
    "p.add_tools(\n",
    "    HoverTool(tooltips = [(\"Borough\", \"@boros\"),\n",
    "                          (\"Listings\", \"@counts\"),\n",
    "                          (\"Median Price\", \"$@price/night\")]\n",
    "             )\n",
    ")\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 5.2: For a Map\n",
    "\n",
    "This is not the prettiest code, but it should work..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure\n",
    "from bokeh.tile_providers import CARTODBPOSITRON, get_provider\n",
    "\n",
    "from bokeh.io import output_file, show, output_notebook, push_notebook, export_png\n",
    "from bokeh.models import ColumnDataSource, GeoJSONDataSource, LinearColorMapper, ColorBar, HoverTool\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.palettes import brewer\n",
    "\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I cobbled the mapping functions below together from two tutorials I found online ([this one](https://github.com/dmnfarrell/teaching/blob/master/geo/maps_python.ipynb) and [this one](https://widdowquinn.github.io/Teaching-Data-Visualisation/exercises/interactive_bokeh_map/interactive_bokeh_map.html)). As you can see, this is a very different approach to mapping data, but it has clear benefits for exploratory purposes and produces fast, interactive maps... and I've not even added selection and filtering tools!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_geodatasource(gdf):    \n",
    "    \"\"\"Get getjsondatasource from geopandas object\"\"\"\n",
    "    json_data = json.dumps(json.loads(gdf.to_json()))\n",
    "    return GeoJSONDataSource(geojson = json_data)\n",
    "\n",
    "def bokeh_plot_map(gdf, column=None, title=''):\n",
    "    \"\"\"Plot bokeh map from GeoJSONDataSource \"\"\"\n",
    "    \n",
    "    tile_provider = get_provider(CARTODBPOSITRON)\n",
    "\n",
    "    geosource = get_geodatasource(gdf)\n",
    "    palette = brewer['OrRd'][8]\n",
    "    palette = palette[::-1]\n",
    "    vals = gdf[column]\n",
    "    \n",
    "    #Instantiate LinearColorMapper that linearly maps numbers in a range, into a sequence of colors.\n",
    "    color_mapper = LinearColorMapper(palette=palette, low=vals.min(), high=vals.max())\n",
    "    color_bar = ColorBar(color_mapper=color_mapper, label_standoff=8, width=500, height=10,\n",
    "                         location=(0,0), orientation='horizontal')\n",
    "\n",
    "    tools = 'wheel_zoom,pan,reset,hover'\n",
    "    \n",
    "    p = figure(title = title, plot_height=700, plot_width=850, toolbar_location='right', tools=tools)\n",
    "    p.add_tile(tile_provider)\n",
    "    p.xgrid.grid_line_color = None\n",
    "    p.ygrid.grid_line_color = None\n",
    "    \n",
    "    # Add patch renderer to figure\n",
    "    p.patches('xs','ys', source=geosource, fill_alpha=0.5, line_width=0.5, line_color='white',  \n",
    "              fill_color={'field' :column , 'transform': color_mapper})\n",
    "    \n",
    "    # Specify figure layout.\n",
    "    p.add_layout(color_bar, 'below')\n",
    "    \n",
    "    # Add hover\n",
    "    hover = p.select_one(HoverTool)\n",
    "    hover.point_policy = \"follow_mouse\"\n",
    "    hover.tooltips = [(\"Borough\", \"@Borough\"),\n",
    "                      (\"Name\", \"@msoa11hclnm\"),\n",
    "                      (\"Listings\", \"@listings\"),\n",
    "                      (\"Median Price\", \"£@price\")]\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, spatially join individual listings to MSOAs. You will need to think about the `how` here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msoadf  = gpd.sjoin(??, ??, how=??, op=??)\n",
    "msoadf.sample(3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then group by and aggregate based on median price and count. Notice how the output from this differs subtly from what you'd get with `{'price':['median','count']}`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msoagrdf2 = msoadf.groupby('MSOA11NM').agg({'price':['median'],'room_type':['count']}).reset_index()\n",
    "msoagrdf2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset the levels and fix the column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msoagrdf2.columns = msoagrdf2.columns.get_level_values(0)\n",
    "msoagrdf2.rename(columns={'room_type':'listings'}, inplace=True)\n",
    "msoagrdf2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the data range(s) and resolve any apparent issues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msoagrdf2.sort_values(by='price', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msoagrdf2.loc[??,??] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the results of any modification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msoagrdf2.sort_values(by='price', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the MSOA GPKG file that we saved earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msoas = gpd.read_file(os.path.join('data','geo','London_MSOAs.gpkg'))\n",
    "msoageo = pd.merge(msoas, msoagrdf2, on='MSOA11NM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reproject to Web Mercator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msoageo = msoageo.to_crs('epsg:3785')\n",
    "msoageo.total_bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And map it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = bokeh_plot_map(msoageo, 'price', title='MSOA-Level Activity')\n",
    "\n",
    "handle = show(p, notebook_handle=True)\n",
    "push_notebook(handle=handle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
